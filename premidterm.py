# -*- coding: utf-8 -*-
"""preMidterm.ipynb

Automatically generated by Colaboratory.


"""

import pandas as pd
import numpy as np

df=pd.read_csv('survival.csv',header=0)
df.head()

df.info()

"""### Data Preprocessing"""

# Dropping irrelevant columns
df.drop(['encounter_id','patient_id','hospital_id','icu_id','Unnamed: 83'],inplace=True,axis=1)

df.describe()

# Dealing with negative probabilities
df.drop(df[(df['apache_4a_hospital_death_prob'] <0)].index, inplace=True)
df.drop(df[(df['apache_4a_icu_death_prob'] <0)].index, inplace=True)
df.describe()

df=df.fillna(df.median()) #Mean imputation for numeric features

df = df.fillna(df.mode().iloc[0]) # Mode imputation for categorical features

# Variable distribution

#Plotting the counts
import matplotlib.pyplot as plt
import seaborn as sns
for col in df.columns:
    plt.figure(figsize=(20,8))
    sns.histplot(df[col], color="blue")
    plt.show()

"""### Relationship study"""

# Relationship count
def plotOccurence(data,colname,label):
    plot=pd.crosstab(index=data[colname],columns=data[label]).plot(kind='bar',stacked=True,figsize=(16,5))
    plt.xlabel(colname)
    plt.ylabel('Count')
    plt.grid(axis='y',linestyle='-')
    plt.title(colname+" vs "+label+" count")

for label in df.columns:
    plotOccurence(df,label,'hospital_death')
    #plotProportion(df,label,'hospital_death')

# Dropping more columns
df.drop(['aids','leukemia','lymphoma'],inplace=True,axis=1)

# Outlier treatment
for col in df.columns:
    if df[col].dtype=='int64' or df[col].dtype=='float64':
        uq=np.percentile(df[col],[99])[0] #Upper Quartile
        df[col][(df[col] > 3*uq)] = 3*uq
        #print(df[col][(df[col] > 3*uq)])
        lq=np.percentile(df[col],[1])[0] #Lower quartile
        df[col][(df[col] < 0.3*lq)] = 0.3*lq
        #print(df[col][(df[col] < 0.3*lq)])

#Generating dummy variables
df=pd.get_dummies(df, columns=['ethnicity','gender','icu_admit_source','icu_stay_type','icu_type','apache_3j_bodysystem','apache_2_bodysystem'],drop_first=True)
df.info()

#Basic model
X=df.loc[:,df.columns!='hospital_death']
Y=df['hospital_death']

"""### Logistic Regression without standardization"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=42)
model1=LogisticRegression()
model1.fit(X_train,Y_train)
print(classification_report(Y_test,model1.predict(X_test)))

#Standardization
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
scaler.fit(X_train)
X_train=scaler.transform(X_train)
scaler.fit(X_test)
X_test=scaler.transform(X_test)

"""### Logistic Regression with Standardization"""

#Logistic Regression
model2=LogisticRegression()
model2.fit(X_train,Y_train)
print(classification_report(Y_test,model2.predict(X_test)))

"""### Support Vector Machines"""

#Support Vector machines
from sklearn.svm import SVC
model3 = SVC()
model3.fit(X_train,Y_train)
print(classification_report(Y_test,model3.predict(X_test)))

"""### Decision Tree"""

#Decision Tree
from sklearn.tree import DecisionTreeClassifier
model4=DecisionTreeClassifier(max_depth=10,random_state=42)
model4.fit(X_train,Y_train)
print(classification_report(Y_test,model4.predict(X_test)))

"""### Naive Bayes"""

#Naive Bayes
from sklearn.naive_bayes import GaussianNB
model5=GaussianNB()
model5.fit(X_train,Y_train)
print(classification_report(Y_test,model5.predict(X_test)))