{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score,StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SUGAM\\AppData\\Local\\Temp/ipykernel_14232/1734991675.py:7: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df=df.fillna(df.median()) #Mean imputation for numeric features\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('survival.csv',header=0)\n",
    "# Dropping irrelevant columns\n",
    "df.drop(['encounter_id','patient_id','hospital_id','icu_id','Unnamed: 83'],inplace=True,axis=1)\n",
    "# Dealing with negative probabilities\n",
    "df.drop(df[(df['apache_4a_hospital_death_prob'] <0)].index, inplace=True)\n",
    "df.drop(df[(df['apache_4a_icu_death_prob'] <0)].index, inplace=True)\n",
    "df=df.fillna(df.median()) #Mean imputation for numeric features\n",
    "df = df.fillna(df.mode().iloc[0]) # Mode imputation for categorical features\n",
    "# Dropping more columns\n",
    "df.drop(['aids','leukemia','lymphoma'],inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SUGAM\\AppData\\Local\\Temp/ipykernel_14232/317258353.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col][(df[col] > 3*uq)] = 3*uq\n",
      "C:\\Users\\SUGAM\\AppData\\Local\\Temp/ipykernel_14232/317258353.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col][(df[col] < 0.3*lq)] = 0.3*lq\n"
     ]
    }
   ],
   "source": [
    "# Outlier treatment\n",
    "for col in df.columns:\n",
    "    if df[col].dtype=='int64' or df[col].dtype=='float64':\n",
    "        uq=np.percentile(df[col],[99])[0] #Upper Quartile\n",
    "        df[col][(df[col] > 3*uq)] = 3*uq\n",
    "        lq=np.percentile(df[col],[1])[0] #Lower quartile\n",
    "        df[col][(df[col] < 0.3*lq)] = 0.3*lq\n",
    "\n",
    "#Generating dummy variables\n",
    "df=pd.get_dummies(df, columns=['ethnicity','gender','icu_admit_source','icu_stay_type','icu_type','apache_3j_bodysystem','apache_2_bodysystem'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bmi', 'elective_surgery', 'height', 'pre_icu_los_days',\n",
       "       'weight', 'apache_2_diagnosis', 'apache_3j_diagnosis',\n",
       "       'apache_post_operative', 'arf_apache',\n",
       "       ...\n",
       "       'apache_3j_bodysystem_Trauma', 'apache_2_bodysystem_Gastrointestinal',\n",
       "       'apache_2_bodysystem_Haematologic', 'apache_2_bodysystem_Metabolic',\n",
       "       'apache_2_bodysystem_Neurologic',\n",
       "       'apache_2_bodysystem_Renal/Genitourinary',\n",
       "       'apache_2_bodysystem_Respiratory', 'apache_2_bodysystem_Trauma',\n",
       "       'apache_2_bodysystem_Undefined Diagnoses',\n",
       "       'apache_2_bodysystem_Undefined diagnoses'],\n",
       "      dtype='object', length=108)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89021, 107)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic model\n",
    "X=df.loc[:,df.columns!='hospital_death']\n",
    "Y=df['hospital_death']\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model,X,Y):\n",
    "    cfv = StratifiedKFold(n_splits=10, random_state=5, shuffle=True)\n",
    "    scores = cross_val_score(model, X, Y, scoring='f1', cv=cfv, n_jobs=-1)\n",
    "    scores1 = cross_val_score(model, X, Y, scoring='precision', cv=cfv, n_jobs=-1)\n",
    "    scores2 = cross_val_score(model, X, Y, scoring='recall', cv=cfv, n_jobs=-1)\n",
    "    print(\"Precison Score: \",np.mean(scores1))\n",
    "    print(\"Recall Score: \",np.mean(scores2))\n",
    "    print(\"F1 Score: \",np.mean(scores),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.6562712698379758\n",
      "Recall Score:  0.2848587797563325\n",
      "F1 Score:  0.39716064511894594 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     24443\n",
      "           1       0.64      0.28      0.39      2264\n",
      "\n",
      "    accuracy                           0.93     26707\n",
      "   macro avg       0.79      0.63      0.67     26707\n",
      "weighted avg       0.91      0.93      0.91     26707\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "lrm=LogisticRegression(random_state=42)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm,X,Y)\n",
    "lrm.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "\n",
    "cc=ClusterCentroids(sampling_strategy='majority',random_state=52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under,Y_under=cc.fit_resample(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.7685631082321673\n",
      "Recall Score:  0.7542709890012629\n",
      "F1 Score:  0.7613182873773129 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      2282\n",
      "           1       0.77      0.75      0.76      2319\n",
      "\n",
      "    accuracy                           0.76      4601\n",
      "   macro avg       0.76      0.76      0.76      4601\n",
      "weighted avg       0.76      0.76      0.76      4601\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lrm1=LogisticRegression(random_state=42)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm1,X_under,Y_under)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_under,Y_under,test_size=0.3,random_state=42)\n",
    "lrm1.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling\n",
    "\n",
    "X_new=X.astype(np.uint8)\n",
    "Y_new=Y.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt=SMOTE(sampling_strategy='minority',k_neighbors=5,random_state=42)\n",
    "X_over,Y_over=smt.fit_resample(X_new,Y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_new=Y.astype(np.uint8)\n",
    "smt=SMOTE(sampling_strategy='minority',k_neighbors=5,random_state=42)\n",
    "X_over,Y_over=smt.fit_resample(X_new,Y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.9248638821213564\n",
      "Recall Score:  0.8776947863577934\n",
      "F1 Score:  0.9006453857958698 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     24265\n",
      "           1       0.92      0.89      0.90     24548\n",
      "\n",
      "    accuracy                           0.91     48813\n",
      "   macro avg       0.91      0.91      0.91     48813\n",
      "weighted avg       0.91      0.91      0.91     48813\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lrm2=LogisticRegression(random_state=42,max_iter=150)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm2,X_over,Y_over)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_over,Y_over,test_size=0.3,random_state=42)\n",
    "lrm2.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined resampling\n",
    "\n",
    "stmk=SMOTETomek(random_state=42)\n",
    "X_comb,Y_comb=stmk.fit_resample(X_new,Y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.9267990335947193\n",
      "Recall Score:  0.8858116994195072\n",
      "F1 Score:  0.9058202590452424 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     24070\n",
      "           1       0.92      0.89      0.91     24198\n",
      "\n",
      "    accuracy                           0.91     48268\n",
      "   macro avg       0.91      0.91      0.91     48268\n",
      "weighted avg       0.91      0.91      0.91     48268\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lrm3=LogisticRegression(random_state=42,max_iter=150)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm3,X_comb,Y_comb)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_comb,Y_comb,test_size=0.3,random_state=42)\n",
    "lrm3.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering -2 \n",
    "\n",
    "sfm_selector = SelectFromModel(estimator=LogisticRegression()).fit(X,Y)\n",
    "X=sfm_selector.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.6490027907462363\n",
      "Recall Score:  0.27325002297786294\n",
      "F1 Score:  0.3844379094220817 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     24443\n",
      "           1       0.63      0.27      0.38      2264\n",
      "\n",
      "    accuracy                           0.92     26707\n",
      "   macro avg       0.78      0.63      0.67     26707\n",
      "weighted avg       0.91      0.92      0.91     26707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrm4=LogisticRegression(random_state=42)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm4,X,Y)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=42)\n",
    "lrm4.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.7337181865740918\n",
      "Recall Score:  0.7347078066863879\n",
      "F1 Score:  0.7340687244268163 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73      2282\n",
      "           1       0.74      0.73      0.73      2319\n",
      "\n",
      "    accuracy                           0.73      4601\n",
      "   macro avg       0.73      0.73      0.73      4601\n",
      "weighted avg       0.73      0.73      0.73      4601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#UnderSampling\n",
    "X_under,Y_under=cc.fit_resample(X,Y)\n",
    "lrm5=LogisticRegression(random_state=42)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm5,X_under,Y_under)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_under,Y_under,test_size=0.3,random_state=42)\n",
    "lrm5.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm5.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.865247873002321\n",
      "Recall Score:  0.6795116682651832\n",
      "F1 Score:  0.7611451966740439 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81     24265\n",
      "           1       0.87      0.67      0.76     24548\n",
      "\n",
      "    accuracy                           0.78     48813\n",
      "   macro avg       0.80      0.78      0.78     48813\n",
      "weighted avg       0.80      0.78      0.78     48813\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#oversampling with feature engineering \n",
    "\n",
    "X_new=X.astype(np.uint8)\n",
    "Y_new=Y.astype(np.uint8)\n",
    "smt=SMOTE(sampling_strategy='minority',k_neighbors=5,random_state=42)\n",
    "X_over,Y_over=smt.fit_resample(X_new,Y_new)\n",
    "\n",
    "lrm2=LogisticRegression(random_state=42,max_iter=150)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm2,X_over,Y_over)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_over,Y_over,test_size=0.3,random_state=42)\n",
    "lrm2.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.8726618847243403\n",
      "Recall Score:  0.6822731715350215\n",
      "F1 Score:  0.7657796476912063 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.89      0.81     24111\n",
      "           1       0.86      0.69      0.77     24074\n",
      "\n",
      "    accuracy                           0.79     48185\n",
      "   macro avg       0.80      0.79      0.79     48185\n",
      "weighted avg       0.80      0.79      0.79     48185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Combined resampling\n",
    "\n",
    "stmk=SMOTETomek(random_state=42)\n",
    "X_comb,Y_comb=stmk.fit_resample(X_new,Y_new)\n",
    "\n",
    "lrm3=LogisticRegression(random_state=42,max_iter=150)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm3,X_comb,Y_comb)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_comb,Y_comb,test_size=0.3,random_state=42)\n",
    "lrm3.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89021, 107)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(89021, 50)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering technique 2 : selectK Best \n",
    "\n",
    "print(X.shape)\n",
    "len(X)\n",
    "X_clf = SelectKBest(score_func=f_regression,k=50).fit_transform(X,Y)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_clf,Y,test_size=0.3,random_state=42)\n",
    "\n",
    "X_clf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.6518871113366381\n",
      "Recall Score:  0.2754690037139035\n",
      "F1 Score:  0.38711266527491806 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     24443\n",
      "           1       0.63      0.27      0.38      2264\n",
      "\n",
      "    accuracy                           0.92     26707\n",
      "   macro avg       0.78      0.63      0.67     26707\n",
      "weighted avg       0.91      0.92      0.91     26707\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#normal lrm \n",
    "lrm=LogisticRegression(random_state=42,max_iter=100)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm,X_clf,Y)\n",
    "lrm.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.7269017041798078\n",
      "Recall Score:  0.7270105630087044\n",
      "F1 Score:  0.7268751011421173 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.73      2282\n",
      "           1       0.73      0.71      0.72      2319\n",
      "\n",
      "    accuracy                           0.72      4601\n",
      "   macro avg       0.72      0.72      0.72      4601\n",
      "weighted avg       0.72      0.72      0.72      4601\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#UnderSampling\n",
    "X_under,Y_under=cc.fit_resample(X_clf,Y)\n",
    "lrm5=LogisticRegression(random_state=42)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm5,X_under,Y_under)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_under,Y_under,test_size=0.3,random_state=42)\n",
    "lrm5.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm5.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.901590813544012\n",
      "Recall Score:  0.7905449038140184\n",
      "F1 Score:  0.8423126620940742 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87     24265\n",
      "           1       0.91      0.79      0.85     24548\n",
      "\n",
      "    accuracy                           0.86     48813\n",
      "   macro avg       0.86      0.86      0.86     48813\n",
      "weighted avg       0.86      0.86      0.86     48813\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#oversampling with feature engineering \n",
    "\n",
    "X_new=X_clf.astype(np.uint8)\n",
    "Y_new=Y.astype(np.uint8)\n",
    "smt=SMOTE(sampling_strategy='minority',k_neighbors=5,random_state=42)\n",
    "X_over,Y_over=smt.fit_resample(X_new,Y_new)\n",
    "\n",
    "lrm2=LogisticRegression(random_state=42,max_iter=150)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm2,X_over,Y_over)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_over,Y_over,test_size=0.3,random_state=42)\n",
    "lrm2.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.8016775170943065\n",
      "Recall Score:  0.7656111652008057\n",
      "F1 Score:  0.7832197924492446 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79     24223\n",
      "           1       0.80      0.76      0.78     24589\n",
      "\n",
      "    accuracy                           0.79     48812\n",
      "   macro avg       0.79      0.79      0.79     48812\n",
      "weighted avg       0.79      0.79      0.79     48812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mixed sampling \n",
    "\n",
    "stmk=SMOTETomek(random_state=42)\n",
    "X_comb,Y_comb=stmk.fit_resample(X_clf,Y)\n",
    "\n",
    "lrm3=LogisticRegression(random_state=42,max_iter=150)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm3,X_comb,Y_comb)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_comb,Y_comb,test_size=0.3,random_state=42)\n",
    "lrm3.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89021, 29)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(89021, 29)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering technique 2 : selectK Best \n",
    "\n",
    "print(X.shape)\n",
    "len(X)\n",
    "X_clf = SelectKBest(score_func=f_regression,k='all').fit_transform(X,Y)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_clf,Y,test_size=0.3,random_state=42)\n",
    "\n",
    "X_clf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.6490027907462363\n",
      "Recall Score:  0.27325002297786294\n",
      "F1 Score:  0.3844379094220817 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     24443\n",
      "           1       0.63      0.27      0.38      2264\n",
      "\n",
      "    accuracy                           0.92     26707\n",
      "   macro avg       0.78      0.63      0.67     26707\n",
      "weighted avg       0.91      0.92      0.91     26707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#normal lrm \n",
    "lrm=LogisticRegression(random_state=42)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm,X_clf,Y)\n",
    "lrm.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.7337181865740918\n",
      "Recall Score:  0.7347078066863879\n",
      "F1 Score:  0.7340687244268163 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73      2282\n",
      "           1       0.74      0.73      0.73      2319\n",
      "\n",
      "    accuracy                           0.73      4601\n",
      "   macro avg       0.73      0.73      0.73      4601\n",
      "weighted avg       0.73      0.73      0.73      4601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#UnderSampling\n",
    "X_under,Y_under=cc.fit_resample(X_clf,Y)\n",
    "lrm5=LogisticRegression(random_state=42)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm5,X_under,Y_under)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_under,Y_under,test_size=0.3,random_state=42)\n",
    "lrm5.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm5.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.865247873002321\n",
      "Recall Score:  0.6795116682651832\n",
      "F1 Score:  0.7611451966740439 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81     24265\n",
      "           1       0.87      0.67      0.76     24548\n",
      "\n",
      "    accuracy                           0.78     48813\n",
      "   macro avg       0.80      0.78      0.78     48813\n",
      "weighted avg       0.80      0.78      0.78     48813\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#oversampling with feature engineering \n",
    "\n",
    "X_new=X.astype(np.uint8)\n",
    "Y_new=Y.astype(np.uint8)\n",
    "smt=SMOTE(sampling_strategy='minority',k_neighbors=5,random_state=42)\n",
    "X_over,Y_over=smt.fit_resample(X_new,Y_new)\n",
    "\n",
    "lrm2=LogisticRegression(random_state=42,max_iter=150)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm2,X_over,Y_over)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_over,Y_over,test_size=0.3,random_state=42)\n",
    "lrm2.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 10 fold cross validation scores:\n",
      "Precison Score:  0.8021235958911372\n",
      "Recall Score:  0.7558445243326462\n",
      "F1 Score:  0.7782910066696015 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79     24300\n",
      "           1       0.81      0.76      0.78     24491\n",
      "\n",
      "    accuracy                           0.79     48791\n",
      "   macro avg       0.79      0.79      0.79     48791\n",
      "weighted avg       0.79      0.79      0.79     48791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mixed sampling \n",
    "\n",
    "stmk=SMOTETomek(random_state=42)\n",
    "X_comb,Y_comb=stmk.fit_resample(X_clf,Y)\n",
    "\n",
    "lrm3=LogisticRegression(random_state=42,max_iter=150)\n",
    "print('Stratified 10 fold cross validation scores:')\n",
    "cross_val(lrm3,X_comb,Y_comb)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_comb,Y_comb,test_size=0.3,random_state=42)\n",
    "lrm3.fit(X_train,Y_train)\n",
    "print(classification_report(Y_test,lrm3.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation (SMOTETomek without resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExplainableBoostingClassifier(feature_names=[&#x27;feature_0001&#x27;, &#x27;feature_0002&#x27;,\n",
       "                                             &#x27;feature_0003&#x27;, &#x27;feature_0004&#x27;,\n",
       "                                             &#x27;feature_0005&#x27;, &#x27;feature_0006&#x27;,\n",
       "                                             &#x27;feature_0007&#x27;, &#x27;feature_0008&#x27;,\n",
       "                                             &#x27;feature_0009&#x27;, &#x27;feature_0010&#x27;,\n",
       "                                             &#x27;feature_0011&#x27;, &#x27;feature_0012&#x27;,\n",
       "                                             &#x27;feature_0013&#x27;, &#x27;feature_0014&#x27;,\n",
       "                                             &#x27;feature_0015&#x27;, &#x27;feature_0016&#x27;,\n",
       "                                             &#x27;feature_0017&#x27;, &#x27;feature_0018&#x27;,\n",
       "                                             &#x27;feature_0019&#x27;, &#x27;feature_0020&#x27;,\n",
       "                                             &#x27;feat...\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;categorical&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExplainableBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>ExplainableBoostingClassifier(feature_names=[&#x27;feature_0001&#x27;, &#x27;feature_0002&#x27;,\n",
       "                                             &#x27;feature_0003&#x27;, &#x27;feature_0004&#x27;,\n",
       "                                             &#x27;feature_0005&#x27;, &#x27;feature_0006&#x27;,\n",
       "                                             &#x27;feature_0007&#x27;, &#x27;feature_0008&#x27;,\n",
       "                                             &#x27;feature_0009&#x27;, &#x27;feature_0010&#x27;,\n",
       "                                             &#x27;feature_0011&#x27;, &#x27;feature_0012&#x27;,\n",
       "                                             &#x27;feature_0013&#x27;, &#x27;feature_0014&#x27;,\n",
       "                                             &#x27;feature_0015&#x27;, &#x27;feature_0016&#x27;,\n",
       "                                             &#x27;feature_0017&#x27;, &#x27;feature_0018&#x27;,\n",
       "                                             &#x27;feature_0019&#x27;, &#x27;feature_0020&#x27;,\n",
       "                                             &#x27;feat...\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;categorical&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;,\n",
       "                                             &#x27;continuous&#x27;, &#x27;continuous&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExplainableBoostingClassifier(feature_names=['feature_0001', 'feature_0002',\n",
       "                                             'feature_0003', 'feature_0004',\n",
       "                                             'feature_0005', 'feature_0006',\n",
       "                                             'feature_0007', 'feature_0008',\n",
       "                                             'feature_0009', 'feature_0010',\n",
       "                                             'feature_0011', 'feature_0012',\n",
       "                                             'feature_0013', 'feature_0014',\n",
       "                                             'feature_0015', 'feature_0016',\n",
       "                                             'feature_0017', 'feature_0018',\n",
       "                                             'feature_0019', 'feature_0020',\n",
       "                                             'feat...\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'categorical', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous',\n",
       "                                             'continuous', 'continuous', ...])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "ebm = ExplainableBoostingClassifier()\n",
    "ebm.fit(X_comb, Y_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\interpret\\visual\\udash.py:5: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n",
      "c:\\Python39\\lib\\site-packages\\interpret\\visual\\udash.py:6: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n",
      "c:\\Python39\\lib\\site-packages\\interpret\\visual\\udash.py:7: UserWarning: \n",
      "The dash_table package is deprecated. Please replace\n",
      "`import dash_table` with `from dash import dash_table`\n",
      "\n",
      "Also, if you're using any of the table format helpers (e.g. Group), replace \n",
      "`from dash_table.Format import Group` with \n",
      "`from dash.dash_table.Format import Group`\n",
      "  import dash_table as dt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/2236926596096/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/2236926596096/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret import show\n",
    "\n",
    "ebm_global = ebm.explain_global()\n",
    "show(ebm_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/2236364868960/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/2236364868960/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X_comb,Y_comb,test_size=0.3,random_state=42)\n",
    "ebm_local = ebm.explain_local(X_test, Y_test)\n",
    "show(ebm_local)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
